{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telegram API Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "def send_alert(filename, alert_type, method='photo'):   # 'photo', 'document', animation\n",
    "    with open('bot_cred.json','r') as json_file:\n",
    "        bot_creds = json.load(json_file)\n",
    "        \n",
    "    files = {method:open(filename, 'rb')}\n",
    "    \n",
    "    resp = requests.post('https://api.telegram.org/bot' + bot_creds['bot_token'] + \\\n",
    "        '/send'+ method + '?chat_id=' + str(bot_creds['bot_chatID']) + '&caption=' + alert_type, files=files)\n",
    "\n",
    "    return resp.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_alert('image1.jpg', 'Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 13:29:46.402112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/np/anaconda3/envs/notifier/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-02-16 13:29:46.402144: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 13:30:58.249796: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-02-16 13:30:58.249892: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: dell\n",
      "2022-02-16 13:30:58.249920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: dell\n",
      "2022-02-16 13:30:58.250104: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.47.3\n",
      "2022-02-16 13:30:58.250180: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.47.3\n",
      "2022-02-16 13:30:58.250203: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.47.3\n",
      "2022-02-16 13:30:58.250789: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# importing model files\n",
    "\n",
    "print(\"Downloading Model files\")\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/efficientdet/lite2/detection/1\")\n",
    "labels = pd.read_csv('labels.csv', sep=';', index_col='ID')\n",
    "labels = labels['OBJECT (2017 REL.)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining width and height of input image\n",
    "\n",
    "width = 512\n",
    "height = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = 0 # \"/dev/video2\" for external webcam on my system\n",
    "cap = cv2.VideoCapture(webcam) \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    # Resize to input_shape\n",
    "    inp = cv2.resize(frame, (width, height))\n",
    "\n",
    "    # Convert to RGB\n",
    "    rgb = cv2.cvtColor(inp, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    rgb_tensor = tf.convert_to_tensor(rgb, dtype=tf.uint8)\n",
    "    rgb_tensor = tf.expand_dims(rgb_tensor, 0)\n",
    "\n",
    "    # predictions\n",
    "    boxes, scores, classes, num_detections = detector(rgb_tensor)\n",
    "\n",
    "    pred_labels = classes.numpy().astype('int')[0]\n",
    "    pred_labels = [labels[i] for i in pred_labels]\n",
    "    pred_boxes = boxes.numpy()[0].astype('int')\n",
    "    pred_scores = scores.numpy()[0]\n",
    "\n",
    "    # loop throughtout the detections and place a box around it\n",
    "    for score, (ymin, xmin, ymax, xmax), label in zip(pred_scores, pred_boxes, pred_labels):\n",
    "        if score < 0.5:\n",
    "            continue\n",
    "        score_txt = f'{100 * round(score,0)}'\n",
    "        img_boxes = cv2.rectangle(rgb, (xmin, ymax), (xmax, ymin), (255,255,255), 1)\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        cv2.putText(img_boxes,label,(xmin, ymax-10), font, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(img_boxes,score_txt,(xmax, ymax-10), font, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        if label == 'person' and (time.time() % 15) < 2:\n",
    "            start = time.time()\n",
    "            cv2.imwrite('alert.jpg', cv2.cvtColor(img_boxes, cv2.COLOR_BGR2RGB))\n",
    "            send_alert('alert.jpg', 'Person Presence')\n",
    "    \n",
    "    #Display the resulting frame\n",
    "    cv2.imshow('black and white',cv2.cvtColor(img_boxes, cv2.COLOR_BGR2RGB))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d5db4ce98fa4b0d97892ea3f0687d35fcee860252bf427f33ad0ef6f6cc0c52"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('notifier')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
